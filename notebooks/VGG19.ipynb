{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CelebA-Spoof for Anti Spoofing using VGG19\n",
    "\n",
    "Muhammad Adisatriyo Pratama - May 2021\n",
    "____________________\n",
    "## Face Antispoofing using Celeb-A Spoof dataset with TensorFlow\n",
    "\n",
    "CelebA-Spoof Dataset Reference:\n",
    "- https://github.com/Davidzhangyuanhan/CelebA-Spoof\n",
    "\n",
    "```script\n",
    "@inproceedings{CelebA-Spoof,\n",
    "  title={CelebA-Spoof: Large-Scale Face Anti-Spoofing Dataset with Rich Annotations},\n",
    "  author={Zhang, Yuanhan and Yin, Zhenfei and Li, Yidong and Yin, Guojun and Yan, Junjie and Shao, Jing and Liu, Ziwei},\n",
    "  booktitle={European Conference on Computer Vision (ECCV)},\n",
    "  year={2020}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic library\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'e:/skripsi/face-anti-spoof-celeba-spoof/dataset/'\n",
    "TRAIN_DIR = data_path + 'train/'\n",
    "TEST_DIR = data_path + 'test/'\n",
    "\n",
    "train_real_dir = os.path.join(TRAIN_DIR, 'real')\n",
    "train_spoof_dir = os.path.join(TRAIN_DIR, 'spoof')\n",
    "\n",
    "testing_real_dir = os.path.join(TEST_DIR, 'real')\n",
    "testing_spoof_dir = os.path.join(TEST_DIR, 'spoof') \n",
    "\n",
    "live_train = os.listdir(train_real_dir)\n",
    "spoof_train = os.listdir(train_spoof_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total training real images :', len(os.listdir(train_real_dir)))\n",
    "print('total training spoof images :', len(os.listdir(train_spoof_dir)))\n",
    "\n",
    "print('total testing real images :', len(os.listdir(testing_real_dir)))\n",
    "print('total testing spoof images :', len(os.listdir(testing_spoof_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Real and Spoof Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def load_img(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image,(224, 224))\n",
    "    return image[...,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(load_img(train_real_dir + \"/\" + live_train[i]), cmap='gray')\n",
    "    plt.suptitle(\"Real faces\",fontsize=20)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(load_img(train_spoof_dir + \"/\" + spoof_train[i]), cmap='gray')\n",
    "    plt.suptitle(\"Spoof faces\",fontsize=20)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow library\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "# ALPHA = 1e-5\n",
    "BATCH_SIZE = 50\n",
    "IMG_SHAPE = (224, 224, 3)\n",
    "EPOCHS = 20\n",
    "# SAMPLE_QTD = 1.0\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "val_share = 0.1\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=val_share,\n",
    "    rotation_range=20,\n",
    "    # width_shift_range=0.15,\n",
    "    # height_shift_range=0.15,\n",
    "    # shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SHAPE[:-1],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SHAPE[:-1],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=IMG_SHAPE[:-1],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)\n",
    "print(val_generator.class_indices)\n",
    "print(test_generator.class_indices)\n",
    "\n",
    "class_names = ['real', 'spoof']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = tf.keras.applications.VGG19(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([vgg19,\n",
    "                                    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
    "                                    tf.keras.layers.BatchNormalization(),\n",
    "                                    tf.keras.layers.Dropout(0.3),\n",
    "                                    tf.keras.layers.Dense(128, activation = \"relu\"),\n",
    "                                    tf.keras.layers.Dropout(0.1),\n",
    "                                    tf.keras.layers.Dense(2, activation='softmax')\n",
    "                                   ])\n",
    "model.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights/transferlearning_weights_VGG19.h5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, \n",
    "                                                monitor='val_accuracy', \n",
    "                                                verbose=1, \n",
    "                                                save_best_only=True, \n",
    "                                                mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    hist = model.fit(train_generator,\n",
    "                    validation_data=val_generator,\n",
    "                    callbacks = [checkpoint],\n",
    "                    epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "\n",
    "loss = hist.history['loss']\n",
    "val_loss = histy.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate testing\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model.evaluate(test_generator)\n",
    "\n",
    "print('---- %s seconds ----' % ((time.time() - start_time)))\n",
    "print('---- %s minutes ----' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted label\n",
    "y_pred = model.predict(test_generator, verbose=1)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "# actual label\n",
    "y_test = test_generator.classes\n",
    "\n",
    "print(y_pred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=test_generator.class_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Predicted Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  true_label, img = true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img.astype(\"uint8\"))\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100 * np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first 30 image from test_images\n",
    "num_rows = 10\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, y_pred[i], y_test, test_generator.filepaths[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/VGG19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "9f5ffc73d3fe4722c46f14bc0a37385bb3ee85ca03a9d520adc4820764bf63c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}